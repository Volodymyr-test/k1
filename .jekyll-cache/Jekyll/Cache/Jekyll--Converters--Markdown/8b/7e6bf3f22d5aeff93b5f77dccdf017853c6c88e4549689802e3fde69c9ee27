I"‡<h1 id="spectral-inference-networks-spin">Spectral Inference Networks (SpIN)</h1>
<p>This package provides an implementation of Spectral Inference Networks,
as in <a href="https://arxiv.org/abs/1806.02215">Pfau, Petersen, Agarwal, Barrett and Stachenfeld (2018)</a>.</p>

<p>This is not an officially supported Google product.</p>

<h2 id="prerequisites">Prerequisites</h2>
<p>SpIN requires a working installation of Python and TensorFlow. We recommend
running it on GPU for faster convergence.</p>

<p>If you want to make use of the GUI (on by default) you will also need Tcl/Tk
installed on your system.</p>

<h2 id="installation">Installation</h2>
<p>After cloning the repo, run pip to install the package and its Python
dependencies:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>spectral_inference_networks
pip <span class="nb">install</span> <span class="nb">.</span>
</code></pre></div></div>

<h2 id="usage">Usage</h2>
<p>Training a spectral inference network is similar to most other deep learning
pipelines: you must construct a data source, network architecture and optimizer.
What makes spectral inference networks unique is that instead of a loss you
provide a linear operator to diagonalize. The code expects an object of the
LinearOperator class, which can be constructed from a similarity kernel or by
other means. LinearOperator objects can be added together or multiplied by a
scalar.</p>

<p>Below is a minimal example of training spectral inference networks:</p>

<p>```python
import tensorflow as tf
import spectral_inference_networks as spin</p>

<p>batch_size = 1024
input_dim = 10
num_eigenvalues = 5
iterations = 1000  # number of training iterations</p>

<h1 id="create-variables-for-simple-mlp">Create variables for simple MLP</h1>
<p>w1 = tf.Variable(tf.random.normal([input_dim, 64]))
w2 = tf.Variable(tf.random.normal([64, num_eigenvalues]))</p>

<p>b1 = tf.Variable(tf.random.normal([64]))
b2 = tf.Variable(tf.random.normal([num_eigenvalues]))</p>

<h1 id="create-function-to-construct-simple-mlp">Create function to construct simple MLP</h1>
<p>def network(x):
  h1 = tf.nn.relu(tf.matmul(x, w1) + b1)
  return tf.matmul(h1, w2) + b2</p>

<p>data = tf.random.normal([batch_size, input_dim])  # replace with actual data</p>
<h1 id="squared-exponential-kernel">Squared exponential kernel.</h1>
<p>kernel = lambda x, y: tf.exp(-(tf.norm(x-y, axis=1, keepdims=True)**2))
linop = spin.KernelOperator(kernel)
optim = tf.train.AdamOptimizer()</p>

<h1 id="constructs-the-internal-training-ops-for-spectral-inference-networks">Constructs the internal training ops for spectral inference networks.</h1>
<p>spectral_net = spin.SpectralNetwork(
    linop,
    network,
    data,
    [w1, w2, b1, b2])</p>

<h1 id="trivial-defaults-for-logging-and-stats-hooks">Trivial defaults for logging and stats hooks.</h1>
<p>logging_config = {
    â€˜configâ€™: {},
    â€˜log_image_everyâ€™: iterations,
    â€˜save_params_everyâ€™: iterations,
    â€˜saver_pathâ€™: â€˜/tmpâ€™,
    â€˜saver_nameâ€™: â€˜exampleâ€™,
}</p>

<p>stats_hooks = {
    â€˜createâ€™: spin.util.create_default_stats,
    â€˜updateâ€™: spin.util.update_default_stats,
}</p>

<h1 id="executes-the-training-of-spectral-inference-networks">Executes the training of spectral inference networks.</h1>
<p>stats = spectral_net.train(
    optim,
    iterations,
    logging_config,
    stats_hooks)</p>
:ET